labsheet 1
EXPERIMENT 1. Creating and pushing changes from local repository to remote repository in GitHub
Problem statement  Create a repository in your local system and Github. Get inside the directory and create a file. Commit changes and push changes to the remote repository
SOLUTION :

git init  //initialize the 
git status
notepad text1.txt
git add text1.txt
git commit -m "my first commit in Demo1"
git log . To check commit log
git remote add origin “https://github.com/namratasgit/demorepo.git”
git push origin master


EXPERIMENT 2a. Branching and Merging [continue experiment 1]
Problem statement  Create and move to a feature branch from the master branch [refer to exp 1], Make necessary changes, commit changes and push changes to remote repository. Switch back to master branch and merge recent commit of feature branch on master branch. 
SOLUTION :

git branch NewBranch  //creating a new branch

git checkout NewBranch //switched to newbranch

notepad demo2.txt

git add .

git commit -m "added demo.txt, my first commit"

git push origin NewBranch  //push New branch commits to remote repository

git checkout master //switch to master branch

git merge NewBranch //merge changes of feature branch with master branch

git push origin master //push the changes to the master branch

git branch -d NewBranch //delete the feature branch from local repository

git push origin --delete NewBranch //delete the feature branch from remote repository


EXPERIMENT 2b. Branching and Merging
Problem statement  Create an add.py and sub.py file in master branch. Create a feature branch, Switch to it and create a multiply.py and div.py file. Move back to master branch, create a mod.py file and perform a merge. Finally push the updated master branch to remote repository in Github
Solution :
//Create a repository in your Github account and local system. Move inside the repo in your local system, open git bash and perform the following actions-
//Master
git init
notepad add.py
git add .
git commit –m “Commit on add”
notepad sub.py
git add .
git commit –m “Commit on sub”
git branch feature
git checkout feature

//Feature
notepad multiply.py
git add .
git commit –m “Commit on multiply”
notepad div.py
git add .
git commit –m “Commit on div”
git checkout master

// Master
notepad mod.py
git add .
git commit –m “Commit on mod”
git merge feature
git remote add origin “http:…..” // add remote repo http link
git push origin master




EXPERIMENT 3. Resolving merge conflicts
a.	Create a new repository in github and add a simple text file with contents-
Hello!
I am developer_name
I am from developer_city
b.	Get into your local systems and create two separate folders named “Alice” and “Bob” in two separate drives.
c.	Get inside both folders and open git bash.
d.	Follow the steps below for each user mentioned-
i.	Both Alice and Bob clones the remote repository from Github
ii.	Both get into the cloned repository.
iii.	Alice creates a feature branch while Bob uses choses to stay in the master branch.
iv.	Feature  Alice switches to the feature branch, creates a text file , commits the changes and switches back to the master branch
Master  Bob creates a text file, commits on the changes and performs a push to the remote repository.
v.	Master   Alice pulls the remote repository, merges the feature branch ‘dev1branch’ to the master branch, gets a conflict and resolves it
vi.	Master   After resolving conflict, the changed file is committed and push to the remote repository. 

SOLUTION :

Alice 									Bob















EXPERIMENT 4 : Git Rebase
	Create a repository in your local machine and perform the following steps-

//Master 
git init
notepad a.txt
git add .
git commit –m “First commit”
git branch feature

//Feature
notepad b.txt
git add .
git commit –m “Seond commit”
git checkout master

//Master
notepad c.txt
git add .
git commit –m “Third commit”
git checkout feature
//Feature
git rebase master
git log 
git checkout master

//Master
notepad d.txt
git add .
git commit –m “Fourth commit”
git log	//to check commit history on master
git checkout feature

//Feature
notepad e.txt
git add .
git commit –m “Fifth commit”
git log  //to check commit history on feature
git rebase master
git log



EXPERIMENT 5: Git stash
	Create a new repository in github and add a simple text file
	Get inside your working directory in local system and perform the following-
git clone https://github.com/namratasgit/stashrepo.git //cloning a remote repo to local system
cd stashrepo   // get into the cloned repo
git init	 
git branch feature1   //create new branch – feature1
git checkout feature1	// switch to feature branch

// perform the following actions
notepad second.txt		
git add .
git stash	// stash the second.txt file
notepad third.txt
git add .
git commit –m “F2”  //commit the third.txt file
git log 
ls
git stash apply
ls
git stash
git checkout main  // switch to main branch
git merge main		// perform merge
git branch feature2   //create new branch – feature2
git checkout feature2	// switch to feature branch 

//perform the following actions
notepad fourth.txt
git add .
git stash		// stash the fourth.txt file
git checkout main		//switch to main branch
git merge main	// perform merge on main
git push origin main	//push changes to github repo



================================================================================================================================================================================================================
  labsheet 2
  LABSHEET 2
DOCKER INSTALLATION AND BASIC DOCKER COMMANDS MANUAL
1. Run Powershell as admin and check for wsl2-
	a. type wsl and check if installed.
	b. if not installed, check the wsl2 installation manual at https://learn.microsoft.com/en-us/windows/wsl/install
c. type wsl --install and install 
d. wsl --set-default-version 2
e. wsl --list --verbose
	f. to change linux distribution, type wsl --list --online
	g. type wsl --install -d <Distribution Name> to install multiple distros
	h. type wsl.exe to check the version after installing
	i. type wsl.exe --status
	j. type wsl.exe –l –v to check the wsl mode
	k. wsl --set-default <distribution_name>

l. wsl.exe -d Ubuntu-22.04 [to launch Ubuntu-22.04]


2. Install Docker Desktop from https://docs.docker.com/desktop/install/windows-install/
3. Create an account in Dockerhub
Basic Commands-
i.	docker info
ii.	docker pull hello-world:latest
iii.	docker images
iv.	docker image COMMAND //displays list of options to work with images  
v.	docker ps
vi.	docker ps –a
vii.	docker run hello-world
viii.	docker inspect <container-id> //to inspect about a container
ix.	docker run --name hellocontainer hello-world //to rename a container
x.	docker run –name <container-name> -i –t –d <image:tag> //to run a container in interactive mode
or
docker run  - -name <container-name> -itd <image:tag>
docker run name <container-name> -it –d <image:tag>

where -i to open image in interactive mode and allow us for standard input or interact with the command-line of the container
    -t  provide an interactive terminal session
   -d  detach( run containers in background and print an ID) 
xi.	docker exec -it <container-name> <image> // to open the terminal
xii.	exit() // to exit from the container terminal
xiii.	docker run - -name <container-name> -i –t <image:tag> // to directly open the interactive terminal session without exec command.
xiv.	docker restart python-c3 //to restart an existing container
xv.	docker rm <container-name>
xvi.	docker rmi <image-id>
xvii.	docker container prune //delete all stopped containers from engine
xviii.	EXPOSING AND PUBLISHING PORT
docker run  - -name nginx-c1 –d –p 8085:80 nginx //binding host machine port to nginx server port(nginx runs in port 80)
The same port can be used by apache web server if you run different container for a different server 
docker run  - -name apache-c1 –d –p 8000:80 httpd
xix.	docker run -d ubuntu sleep 100 // to keep a container for 100 secs
docker exec <container-id>  cat /etc/*release*  //to run a command in a running container

xx.	docker stop <container-name> //to stop a running container
xxi.	docker start <container-name> //to start the same container and start working again
xxii.	 PUSHING IMAGE TO DOCKERHUB
docker tag <image-id>  username/repository
docker login //press enter and provide both username and password of your dockerhub account.
docker push username/repository
xxiii.	USING ENVIRONMENT VARIABLE AND ACCESS MYSQL SHELL
docker pull mysql:latest
docker run - -name mysql-c1 -e MYSQL_ROOT_PASSWORD=<your-password> -d mysql:latest
docker exec -it mysql-c1 mysql -u root -p
 To generate this message, Docker took the following steps:
 1. The Docker client contacted the Docker daemon.
 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
    (amd64)
 3. The Docker daemon created a new container from that image which runs the
    executable that produces the output you are currently reading.
 4. The Docker daemon streamed that output to the Docker client, which sent it
    to your terminal.
==================================================================================================================================================================================================================
labsheet 3

LABSHEET 3
CREATING AND PLAYING WITH IMAGES USING DOCKERFILE
1. Write a simple prompt application that takes the name as user input and leaves a welcome message with the name. Also create a dockerfile to tun the same in nginx
Solution
a. Create an HTML file with the following content
<!DOCTYPE html>
<html>
<head>
    <title>Welcome Page</title>
</head>
<body>
    <h1>Welcome Page</h1>
    <form>
        <label for="name">Enter your name:</label>
        <input type="text" id="name" name="name" required>
        <button type="button" onclick="displayWelcome()">Submit</button>
    </form>
    <p id="welcomeMessage"></p>
    <script>
        function displayWelcome() {
            var name = document.getElementById("name").value;
            var welcomeMessage = document.getElementById("welcomeMessage");
            welcomeMessage.innerHTML = "Welcome, " + name + "!";
        }
    </script>
</body>
</html>


b. Create a dockerfile to serve this html file using NGINX server
# Dockerfile
# Use the official NGINX image as a parent image
FROM nginx
# Copy the HTML file into the container
COPY index.html /usr/share/nginx/html/index.html
# Expose port 80
EXPOSE 80
c. Build the docker image for your HTML application
docker build -t namratasdocker/html-app .
d.	Run a docker container for the image
docker run -d -p 8086:80 namratasdocker/html-app 
e.	Push image to docker hub repository
docker push namratasdocker/html-app

2.  Create a dockerfile that installs Ubuntu and displays a message immediately it runs.
Solution
FROM ubuntu:jammy-20230916

LABEL maintainer="namrata <dasnamrata795@gmail.com>"

LABEL description="This example Dockerfile installs ubuntu and displays a message."

RUN apt-get update

CMD ["echo", "Hello World...! from my first docker image"]

Execute the following commands in your docker cli
docker build –t myubuntuapp .  // to build the Image
docker run - -name myubuntu myapp2  //to run a container for the image.
docker tag   myubuntuapp namratasdocker/repository  // // tag your docker image with your dockerhub repository name. This means associating your image with your docker hub repo and when you push it to the docker hub, it will be stored in that repo under the name ‘namratasdocker/myapp’
docker login //authenticate using credentials
docker push namratasdocker/repository //push image to dockerhub

3. Create a simple dockerfile that uses Ubuntu as the base image and installs apache v2
Solution
FROM ubuntu
RUN apt-get update
RUN apt-get -y install apache2
ADD . /var/www/html
#CMD apachectl -D FOREGROUND
ENTRYPOINT apachectl -D FOREGROUND //to start apache v2, apachectl is a frontend HTTP server
ENV name DevOps

//creating the image, running container and pushing it to dockerhub
docker build -t mydockerfile:latest .
docker run - -name container-c1 -d -p 8086:80 mydockerfile
docker tag mydockerfile namratasdocker/mydockerfile
docker login
docker push namratasdocker/mydockerfile:latest
		
4.  Create a Dockerfile for an image that executes "script.sh" script, and displays a  "Hello World...! from my first docker image" message in the container's standard output.

Solution
a.	Create a script.sh file 
#! /bin/bash	// This is called a shebang line. It specifies the interpreter to be used for the script, which is "/bin/bash" in this case
echo "Hello World...! from my first docker image" 	// the actual command that will be executed when the "script.sh" script is run. It prints the "Hello World...! from my first docker image" message to the standard output of the container.



b.	Create a Dockerfile to build the above application
#The base image you want to use and customize
FROM Ubuntu	 // This line specifies the base image for your Docker image. In this case, you are using the "ubuntu" base image, which provides the Ubuntu Linux operating system.

#Set the working directory inside container
WORKDIR /app     // sets the working directory inside the container to "/app." All subsequent   commands will be executed in this directory.

#Copy a script file to the container
COPY script.sh .	// copies the "script.sh" file from the host system into the "/app" directory of the container. The "." refers to the current directory inside the container.

#Make the script executable
RUN chmod +x script.sh    // makes the "script.sh" file executable within the container by using the "chmod" command.

CMD [ "./script.sh"]	// specifies the command that should be executed when the container starts. It tells Docker to run the "script.sh" script.


5. Create a static index.html file in a directory of your choice, to display any message of your choice
a.	Create a dockerfile in the same directory 
i.	Use nginx as the base image
ii.	Copy the index.html file inside the container image
b.	Create the image and push it to docker hub
c.	Pull it into your docker server, create and run a container

6. Create a Dockerfile to build an image for a Python application that adds two numbers and displays the result


================================================================================================================================================================================================================
  labsheet 4
  1.	Create a simple freestyle project that triggers a job after every 1 minute.
Solution
Log into your Jenkins server-
I.	Go to new item, give a name to your project, select freestyle project and click OK
II.	Give a description to your project(optional)
III.	Under ‘Build Triggers’, select ‘build periodically’ and type * * * * * in the shell
IV.	Under ‘Build Step’, select ‘Execute windows batch command’ and type the following commands-
echo “my first Jenkins project: %date% : %time%”
V.	Save and apply
VI.	Build.
VII.	Disable the project to stop the build triggers.


2.	Create a Jenkins freestyle project that integrates Jenkins with Git to execute a simple java program 
Solution
I.	Write a simple java program and save it as ‘myprog.java’(say) and save it in any directory of your choice. 
II.	Write the java code in step 2.
public class Switch {
    public static void main(String args[]){

        int day = 10;

        switch(day){

            case 1:{
                        System.out.println("Monday");
                        break;
                    }
            case 2:{
                        System.out.println("Tuesday");
                        break;
                    }
            case 3:{
                        System.out.println("Wednesday");
                        break;
                    }
            case 4:{
                        System.out.println("Thursday");
                        break;
                    }
            case 5:{
                        System.out.println("Friday");
                        break;
                    }
            case 6:{
                        System.out.println("Saturday");
                        break;
                    }
            case 7:{
                        System.out.println("Sunday");
                        break;
                    }
            default:{
                        System.out.println("Please enter numbers in the range 1:7");
                        break;
                    }

        }
    }
}
III.	Create a github repository for your project.
IV.	Open gitbash from the local directory consisting of your ‘myprog.java’ file. [Say the directory in your local system is ‘C:\Users\user\Desktop\Namrata_Das_PU\Fall_AY_2023-24\Subject_Handled\DevOps\java\myprog.java’].
V.	Push the project to your repository [mention all steps executed in git bash to push the project to the github repository]
VI.	In your Jenkins server-
a)	Go to new item, give a name to your project, select freestyle project and click OK.
b)	Give a description to your project(optional)
c)	Choose the SCM of your choice, say Git.
d)	Provide the repository URL , credentials(optional, if public) and Branches to build ‘*/master’ (if git branch is master) or ‘*/main’ (if git branch is main)
e)	Under ‘Build Step’, select ‘Execute windows batch command’ and type the following commands-
javac myprog.java
java myprog
f)	Save and apply
g)	Build.

3.	Create a simple Jenkins scripted pipeline.
Solution
In your Jenkins server-
I.	Go to new item, give a name to your project, select pipeline and click OK
II.	Give a description to your project(optional)
III.	Go to pipeline, select the ‘Pipeline Script’ option and copy paste the sample pipeline in the command-line shell as given-
node{
stage('Compile'){
		echo "Compiled Successfully!!";
	}

stage('JUnit') {
		echo "JUnit Passed Succesfully!";
}

stage('Quality-Gate') {
		echo "SonarQube Quality Gate passed succesfully!!";
						/*sh exit ("1");*/
}

stage('Deploy') {
		echo "Pass!";
}
}

IV.	Save and apply
V.	Build.

4.	Create a simple Jenkins declarative pipeline.
Solution

In your Jenkins server-
I.	Go to new item, give a name to your project, select pipeline and click OK
II.	Give a description to your project(optional)
III.	Go to pipeline, select the ‘Pipeline Script’ option and copy paste the sample pipeline in the command-line shell as given-
pipeline {
	agent any
	stages {
		stage('Git-Checkout'){
			steps {
				echo "Checking out from Git Repo";
			}
		}

		stage('Build') {
			steps {
				echo "Building the checkedout project!";
			}
		}

		stage('Unit-Test') {
			steps {
				echo "Running JUnit tests";
			}
		}
		stage('Quality-Gate') {
			steps {
				echo "Verifying Quality Gates";
			}
		}

		stage('Deploy') {
			steps {
				echo "Deploying to stage environments for more tests";
			}
		}
	}
	
		post {
			always {
					echo 'This will always run'
				}
			success {
					echo 'This will run only if successful'
				}
			failure {
					echo 'This will run only if failed'
				}
			unstable {
					echo 'This will run only if the run was marked as unstable'
				}
	    		changed {
					echo 'This will run only if the state of the pipeline has changed'
					echo 'For example, if the pipeline was previously failing but is now successful'
				}
   		 }
}


iv.	Save and apply
v.	Build.

5.	
===========================================================================================================================================================================================================
labsheet 5
Git-Nginx-Jenkins Pipeline

To create a Jenkins pipeline that integrates with Git and deploys your HTML project to an Nginx server on Windows 10, you can follow these steps:
1.	Write an html project ‘index.html’ and save it in any directory of your choice. Say the directory in your local system is ‘C:\Users\user\Desktop\Namrata_Das_PU\Fall_AY_2023-24\Subject_Handled\DevOps\pipeline’.

<!DOCTYPE html>
<html>
    <head>
        <title>Canvas Example</title>
    <style>
        canvas {
            border: 1px solid black;
            }
    </style>
</head>
<body>
    <header>
        <h1>Canvas Example</h1>
        <p>Draw on the canvas by clicking and dragging the mouse</p>
    </header>
    <article>
        <h2>Canvas</h2>
        <canvas id="myCanvas" width="400" height="400" 
        onmousedown="startDrawing(event)" onmousemove="drawLine(event)" 
        onmouseup="stopDrawing(event)"></canvas>
    </article>
<script>
    var canvas = document.getElementById("myCanvas");
    var ctx = canvas.getContext("2d");
    var isDrawing = false;
    function startDrawing(event) {
        isDrawing = true;
        var x = event.clientX - canvas.offsetLeft;
        var y = event.clientY - canvas.offsetTop;
        ctx.beginPath();
        ctx.moveTo(x, y);
    }
    function drawLine(event) {
        if (isDrawing) {
        var x = event.clientX - canvas.offsetLeft;
        var y = event.clientY - canvas.offsetTop;
        ctx.lineTo(x, y);
        ctx.stroke();
    }
    }
    function stopDrawing(event) {
        isDrawing = false;
    }
</script>
</body>


2.	Download and install nginx server in your system and make all necessary configurations.
3.	Create a folder ‘htmldocs’ in your nginx filesystem. This will serve as the root directory for your nginx html project . Say the path to the root is ‘C:\Users\user\Desktop\Namrata_Das_PU\Fall_AY_2023-24\DevOps\installers\nginx-1.24.0\htmldocs’
4.	Create a jenkinsfile named ‘Jenkinsfile’ in the same project directory. 

pipeline {
    agent any

    environment {
        GIT_REPO_URL = 'https://github.com/namratasgit/pipeline1.git'
        NGINX_PATH = 'C:\\Users\\user\\Desktop\\Namrata_Das_PU\\Fall_AY_2023-24\\DevOps\\installers\\nginx-1.24.0\\htmldocs'
    }

    stages {
        stage('Checkout') {
            steps {
                script {
                    // Use the checkout step to clone the Git repository
                    checkout([$class: 'GitSCM', branches: [[name: '*/master']], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], userRemoteConfigs: [[url: GIT_REPO_URL]]])
                }
            }
        }

        stage('Deploy to Nginx') {
            steps {
                script {
                    // Using the Jenkins workspace variable to reference files
                    bat 'xcopy /y "C:\\Users\\user\\Desktop\\Namrata_Das_PU\\Fall_AY_2023-24\\Subject_Handled\\DevOps\\pipeline\\index.html" "%NGINX_PATH%"'
                }
            }
        }
    }

    post {
        success {
            echo 'Pipeline succeeded! You can add additional steps here.'
        }
        failure {
            echo 'Pipeline failed! You may want to take some actions.'
        }
    }
}

The Jenkinsfile consist of two stages-
a.	Checking out from scm
b.	Deploying the project in your nginx server

5.	Create a github repository and push the project to your scm.
6.	In your Jenkins server-
a.	 create a new pipeline
b.	Under Pipeline, select Pipeline Script from SCM.
c.	Choose the SCM of your choice, say Git.
d.	Provide the repository URL and credentials(optional, if public).
e.	Set Branches to build to ‘*/master’
f.	Select script path as Jenkinsfile.
g.	Save and apply
h.	Build.
===============================================================================================================================================================================================================
  labsheet 6
  Integrating Docker and Git with Jenkins

To create a Jenkins freestyle project that integrates with Docker and Git and deploys your HTML project to an Nginx server on your operating system, you can follow these steps:
1.	Write an html program for moving a triangle using u r keys ‘main.html’ and save it in a new folder in your local system
<!DOCTYPE html>
<head>
  <style>
    body {
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
      margin: 0;
    }
    #triangle {
      width: 0;
      height: 0;
      border-left: 50px solid transparent;
      border-right: 50px solid transparent;
      border-bottom: 87px solid red; /* You can change the color and dimensions as needed */
      position: absolute;
    }
  </style>
  <title>Triangle Movement</title>
</head>
<body>
  <div id="triangle"></div>
  <script>
    // JavaScript for moving the triangle
    const triangle = document.getElementById('triangle');
    let posX = 0;
    let posY = 0;

    function moveTriangle() {
      triangle.style.left = posX + 'px';
      triangle.style.top = posY + 'px';
    }

    document.addEventListener('keydown', (event) => {
      const step = 10;

      switch (event.key) {
        case 'ArrowUp':
          posY -= step;
          break;
        case 'ArrowDown':
          posY += step;
          break;
        case 'ArrowLeft':
          posX -= step;
          break;
        case 'ArrowRight':
          posX += step;
          break;
      }

      moveTriangle();
    });

    moveTriangle(); // Initial positioning
  </script>
</body>
</html>

2.	Create a Docker file in your same folder using visual studios and save it with the name Dockerfile with all files extension(Note: Don’t save it with the extension of dockerfile since it might create problem during creating a docker image )
             
       FROM nginx
       COPY main.html /usr/share/nginx/html/main.html
       EXPOSE 80

3.	Push your code into GitHub repository which will act as SCM in Jenkins server

4.	Download and install nginx server in your system and make all necessary configurations. 
 
5.	Create a folder ‘htmldocs’ in your nginx filesystem. This will serve as the root directory for your nginx html project . Say the path to the root is ‘C:\Users\user\Desktop\.....\nginx-1.24.0\htmldocs’

6.	In your Jenkins server:
              
             a. Create a freestyle project, give name to it and click ok
             b. You can assign description (Optional)
             c. In SCM, provide your GitHub Repository URL and click on add repository     (Note: If your repository is private then provide your GitHub credentials under it)
             d. Go to Build steps, choose Execute windows batch command 
               There it acts like your command prompt so it will help you in connecting with docker
             e.  Type these docker commands inside execute windows batch command
                  REM Docker build command
      docker build -t triangle-movement .
 
      REM Docker run command
                  docker run -d -p 2003:80 USERNAME/triangle-movement
 
      REM Docker login (replace USERNAME and PASSWORD with your Docker     Hub credentials)
                  docker login -u USERNAME -p PASSWORD
 
                  REM Push the Docker image to Docker Hub
                  docker push USERNAME/triangle-movement
                  (Note: REM acts like a comment in cmd)
              f.  Click on apply and build it.

7.	Once the freestyle project gets build u can open in your docker desktop In your local system to see your container running.

8.	There you can click on the port number to deploy your project in the nginx server.

9.	You can verify by opening Docker Hub and check for the repository which y=u created.

10.	 If you want to pull the image again and want to deploy in nginx server then   you can just go to the created freestyle project there you can click configure,
             there you can change the commands under execute windows batch
             command:
             
              REM Docker pull command from the repository
              docker pull USERNAME/triangle-movement:latest
 
              REM Docker run command
              docker run -d -p 2003:80 USERNAME/triangle-movement
 
              REM Docker login (replace USERNAME and PASSWORD with your DockerHub
              credentials)
              docker login -u USERNAME -p PASSWORD                        



------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------


Benefits of Ansible
Free: Ansible is an open-source tool.
Very simple to set up and use: No special coding skills are necessary to use Ansible’s playbooks (more on playbooks later).
Powerful: Ansible lets you model even highly complex IT workflows. 
Flexible: You can orchestrate the entire application environment no matter where it’s deployed. You can also customize it based on your needs.
Agentless: You don’t need to install any other software or firewall ports on the client systems you want to automate. You also don’t have to set up a separate management structure.
Efficient: Because you don’t need to install any extra software, there’s more room for application resources on your server.

Ansible playbooks

Ansible Playbooks offer a repeatable, reusable, simple configuration management and multi-machine deployment system, one that is well suited to deploying complex applications. If you need to execute a task with Ansible more than once, write a playbook and put it under source control. Then you can use the playbook to push out new configuration or confirm the configuration of remote systems.
Playbooks can:
declare configurations
orchestrate steps of any manual ordered process, on multiple sets of machines, in a defined order
launch tasks synchronously or asynchronously


Playbook syntax
Playbooks are expressed in YAML format with a minimum of syntax. 
A playbook is composed of one or more ‘plays’ in an ordered list. The terms ‘playbook’ and ‘play’ are sports analogies. Each play executes part of the overall goal of the playbook, running one or more tasks. Each task calls an Ansible module.
EXAMPLE 1

---
- hosts: all
  tasks:
    - name: Print message
      debug:
        msg: Hello Ansible World



EXAMPLE 2

---
- hosts: all
  vars:
    - username: sammy
    - home: /home/sammy   
  tasks:
    - name: print variables
      debug:
        msg: "Username: {{ username }}, Home dir: {{ home }}"

The vars section of the playbook defines a list of variables that will be injected in the scope of that play. All tasks, as well as any file or template that might be included in the playbook, will have access to these variables.


Playbook execution
A playbook runs in order from top to bottom. Within each play, tasks also run in order from top to bottom. Playbooks with multiple ‘plays’ can orchestrate multi-machine deployments, running one play on your webservers, then another play on your database servers, then a third play on your network infrastructure, and so on. At a minimum, each play defines two things:
the managed nodes to target, using a pattern 
at least one task to execute

EXAMPLE 3
In this example, the first play targets the web servers; the second play targets the database servers.
---
- name: Update web servers
  hosts: webservers
  remote_user: root

  tasks:
  - name: Ensure apache is at the latest version
    ansible.builtin.yum:
      name: httpd
      state: latest

  - name: Write the apache config file
    ansible.builtin.template:
      src: /srv/httpd.j2
      dest: /etc/httpd.conf

- name: Update db servers
  hosts: databases
  remote_user: root

  tasks:
  - name: Ensure postgresql is at the latest version
    ansible.builtin.yum:
      name: postgresql
      state: latest

  - name: Ensure that postgresql is started
    ansible.builtin.service:
      name: postgresql
      state: started
Your playbook can include more than just a hosts line and tasks. For example, the playbook above sets a remote user for each play. This is the user account for the SSH connection.

EXAMPLE 4



What is Ansible Inventory?
Ansible can work with multiple systems in your infrastructure at the same time. In order to work with multiple servers, Ansible needs to establish connectivity to those servers. This is done with SSH for Linux and PowerShell remoting for windows that would make Ansible agentless. Agentless means you don’t need to install any additional software on the Target machines to be able to work with Ansible. One of the major disadvantages of other automation tools is that you need to install and configure agents on the Target machines before you can invoke any kind of automation. Now the information about these Target systems is stored in a file called an inventory file. If you don’t create a new inventory file Ansible uses its default inventory file located at /etc/ansible/hosts.
Ansible Modules

Modules (also referred to as “task plugins” or “library plugins”) are discrete units of code that can be used from the command line or in a playbook task. Ansible executes each module, usually on the remote managed node, and collects return values. In Ansible 2.10 and later, most modules are hosted in collections.

Ansible modules are standalone scripts that can be used inside an Ansible playbook. A playbook consists of a play, and a play consists of tasks. These concepts may seem confusing if you're new to Ansible, but as you begin writing and working more with playbooks, they will become familiar There are some modules that are frequently used in automating everyday tasks; those are the ones that we will cover in this article.
 
Ansible has three main files that you need to consider:
Host/inventory file: Contains the entry of the nodes that need to be managed
Ansible.cfg file: Located by default at /etc/ansible/ansible.cfg, it has the necessary privilege escalation options and the location of the inventory file
Main file: A playbook that has modules that perform various tasks on a host listed in an inventory or host file
Module 1: Package management
There is a module for most popular package managers, such as DNF and APT, to enable you to install any package on a system. Functionality depends entirely on the package manager, but usually these modules can install, upgrade, downgrade, remove, and list packages. The names of relevant modules are easy to guess. For example, the DNF module is dnf_module, the old YUM module (required for Python 2 compatibility) is yum_module, while the APT module is apt_module, and so on.
Example 1:
- name: install the latest version of Apache and MariaDB
  dnf:
    name:
      - httpd
      - mariadb-server
    state: latest


This installs the Apache web server and the MariaDB SQL database.
Example 2:

- name: Install a list of packages
  yum:
    name:
      - nginx
      - postgresql
      - postgresql-server
    state: present


This installs the list of packages and helps download multiple packages.
Module 2: Service
After installing a package, you need a module to start it. The service module enables you to start, stop, and reload installed packages; this comes in pretty handy.
Example 1:

- name: Start service foo, based on running process /usr/bin/foo
  service:
    name: foo
    pattern: /usr/bin/foo
    state: started
This starts the service foo.
Example 2:	

- name: Restart network service for interface eth0
  service:
    name: network
    state: restarted
    args: eth0
This restarts the network service of the interface eth0.
Module 3: Copy
The copy module copies a file from the local or remote machine to a location on the remote machine.
Example 1:

- name: Copy a new "ntp.conf file into place, backing up the original if it differs from the copied version
  copy:
    src: /mine/ntp.conf
    dest: /etc/ntp.conf
    owner: root
    group: root
    mode: '0644'
    backup: yes

Module 4: Debug
The debug module prints statements during execution and can be useful for debugging variables or expressions without having to halt the playbook.
Example 1:

- name: Display all variables/facts known for a host
  debug:
    var: hostvars[inventory_hostname]
    verbosity: 4
This displays all the variable information for a host that is defined in the inventory file.


-----------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------

1.What is Jenkins?
Jenkins is an open source automation tool written in Java programming language that allows continuous integration.
Jenkins builds and tests our software projects which continuously making it easier for developers to integrate changes to the project, and making it easier for users to obtain a fresh build.
It also allows us to continuously deliver our software by integrating with a large number of testing and deployment technologies.
Jenkins offers a straightforward way to set up a continuous integration or continuous delivery environment for almost any combination of languages and source code repositories using pipelines, as well as automating other routine development tasks.
With the help of Jenkins, organizations can speed up the software development process through automation. Jenkins adds development life-cycle processes of all kinds, including build, document, test, package, stage, deploy static analysis and much more.
Jenkins achieves CI (Continuous Integration) with the help of plugins. Plugins is used to allow the integration of various DevOps stages. If you want to integrate a particular tool, you have to install the plugins for that tool. For example: Maven 2 Project, Git, HTML Publisher, Amazon EC2, etc.
For example: If any organization is developing a project, then Jenkins will continuously test your project builds and show you the errors in early stages of your development.
Possible steps executed by Jenkins are for example:
Perform a software build using a build system like Gradle or Maven Apache
Execute a shell script
Archive a build result
Running software tests
2.Work Flow:

History of Jenkins
Kohsuke Kawaguchi, who is a Java developer, working at SUN Microsystems, was tired of building the code and fixing errors repetitively. In 2004, he created an automation server called Hudson that automates build and test task.
In 2011, Oracle who owned Sun Microsystems had a dispute with Hudson open source community, so they forked Hudson and renamed it as Jenkins.
Both Hudson and Jenkins continued to operate independently. But in short span of time, Jenkins acquired a lot of contributors and projects while Hudson remained with only 32 projects. Then with time, Jenkins became more popular, and Hudson is not maintained anymore.
What is Continuous Integration?
Continuous Integration (CI) is a development practice in which the developers are needs to commit changes to the source code in a shared repository at regular intervals. Every commit made in the repository is then built. This allows the development teams to detect the problems early.
Continuous integration requires the developers to have regular builds. The general practice is that whenever a code commit occurs, a build should be triggered.
Continuous Integration with Jenkins
Let's consider a scenario where the complete source code of the application was built and then deployed on test server for testing. It sounds like a perfect way to develop software, but this process has many problems.
oDeveloper teams have to wait till the complete software is developed for the test results.
oThere is a high prospect that the test results might show multiple bugs. It was tough for developers to locate those bugs because they have to check the entire source code of the application.
oIt slows the software delivery process.
oContinuous feedback pertaining to things like architectural or coding issues, build failures, test status and file release uploads was missing due to which the quality of software can go down.
oThe whole process was manual which increases the threat of frequent failure.
AD
It is obvious from the above stated problems that not only the software delivery process became slow but the quality of software also went down. This leads to customer dissatisfaction.
So to overcome such problem there was a need for a system to exist where developers can continuously trigger a build and test for every change made in the source code.
This is what Continuous Integration (CI) is all about. Jenkins is the most mature Continuous Integration tool available so let us see how Continuous Integration with Jenkins overcame the above shortcomings.
Let's see a generic flow diagram of Continuous Integration with Jenkins:
AD



Let's see how Jenkins works. The above diagram is representing the following functions:
oFirst of all, a developer commits the code to the source code repository. Meanwhile, the Jenkins checks the repository at regular intervals for changes.
oSoon after a commit occurs, the Jenkins server finds the changes that have occurred in the source code repository. Jenkins will draw those changes and will start preparing a new build.
oIf the build fails, then the concerned team will be notified.
oIf built is successful, then Jenkins server deploys the built in the test server.
oAfter testing, Jenkins server generates a feedback and then notifies the developers about the build and test results.
oIt will continue to verify the source code repository for changes made in the source code and the whole process keeps on repeating.
Advantages and Disadvantages of using Jenkins
Advantages of Jenkins
oIt is an open source tool.
oIt is free of cost.
oIt does not require additional installations or components. Means it is easy to install.
oEasily configurable.
oIt supports 1000 or more plugins to ease your work. If a plugin does not exist, you can write the script for it and share with community.
oIt is built in java and hence it is portable.
oIt is platform independent. It is available for all platforms and different operating systems. Like OS X, Windows or Linux.
oEasy support, since it open source and widely used.
oJenkins also supports cloud based architecture so that we can deploy Jenkins in cloud based platforms.
Disadvantages of Jenkins
oIts interface is out dated and not user friendly compared to current user interface trends.
oNot easy to maintain it because it runs on a server and requires some skills as server administrator to monitor its activity.
oCI regularly breaks due to some small setting changes. CI will be paused and therefore requires some developer's team attention.
Jenkins Architecture
Jenkins follows Master-Slave architecture to manage distributed builds. In this architecture, slave and master communicate through TCP/IP protocol.
Jenkins architecture has two components:
oJenkins Master/Server
oJenkins Slave/Node/Build Server


Jenkins Master
Main Jenkins server is the Master and its job is to handle:
Scheduling build jobs
Dispatching builds to the slaves for the actual execution
Monitoring the slaves (possibly taking them online and offline as required)
Recording and presenting the build results
Executing build jobs directly
Jenkins Slave
A Slave is a Java executable that runs on a remote machine. The following are the characteristics of a Jenkins Slave:
It hears requests from the Jenkins Master instance.
A Slave can run on a variety of operating systems.
The job of a Slave is to “obey” the Master, that is, execute build jobs dispatched by it.
You can either configure a project to always run on a particular (type of) Slave machine or simply let Jenkins pick the next available Slave.

The above diagram is self explanatory. It consists of a Jenkins Master which is managing three Jenkins Slaves.

What is Continuous Delivery Pipeline?
In a Jenkins Pipeline, every job has some sort of dependency on at least one or more jobs or events.


The above diagram represents a continuous delivery pipeline in Jenkins. It contains a collection of states such as build, deploy, test and release. These jobs or events are interlinked with each other. Every state has its jobs, which work in a sequence called a continuous delivery pipeline.
A continuous delivery pipeline is an automated expression to show your process for getting software for version control. Thus, every change made in your software goes through a number of complex processes on its manner to being released. It also involves developing the software in a repeatable and reliable manner, and progression of the built software through multiple stages of testing and deployment.


JenkinsFile
Jenkins Pipeline can be defined by a text file called JenkinsFile. You can implement pipeline as code using JenkinsFile, and this can be defined by using a DSL (Domain Specific Language). With the help of JenkinsFile, you can write the steps required for running a Jenkins Pipeline.
The benefits of using JenkinsFile are:
oYou can make pipelines automatically for all branches and can execute pull requests with just one JenkinsFile.
oYou can review your code on the pipeline.
oYou can review your Jenkins pipeline.
oThis is the singular source for your pipeline and can be customized by multiple users.
JenkinsFile can be defined by using either Web UI or with a JenkinsFile.
Pipeline syntax
Two types of syntax are used for defining your JenkinsFile.
oDeclarative
oScripted
AD
Declarative:
Declarative pipeline syntax offers a simple way to create pipelines. It consists of a predefined hierarchy to create Jenkins pipelines. It provides you the ability to control all aspects of a pipeline execution in a simple, straightforward manner.
Scripted:
Scripted Jenkins pipeline syntax runs on the Jenkins master with the help of a lightweight executor. It uses very few resources to convert the pipeline into atomic commands.
Both scripted and declarative syntax are different from each other and are defined totally differently.
AD
Why Use Jenkins Pipeline?
Jenkins is a continuous integration server which has the ability to support the automation of software development processes. You can create several automation jobs with the help of use cases, and run them as a Jenkins pipeline.
AD
Here are the reasons why you should use Jenkins pipeline:
oJenkins pipeline is implemented as a code which allows several users to edit and execute the pipeline process.
oPipelines are robust. So if your server undergoes an unpredicted restart, the pipeline will be automatically resumed.
oYou can pause the pipeline process and make it wait to continue until there is an input from the user.
oJenkins Pipelines support big projects. You can run many jobs, and even use pipelines in a loop.
Jenkins Pipeline Concepts
Pipeline: This is the user-defined block, which contains all the processes such as build, test, deploy, etc. it is a group of all the stages in a JenkinsFile. All the stages and steps are defined in this block. It is used in declarative pipeline syntax.
pipeline{  
}  
Node: The node is a machine on which Jenkins runs is called a node. A node block is used in scripted pipeline syntax.
node{  
}  
Stage: This block contains a series of steps in a pipeline. i.e., build, test, and deploy processes all come together in a stage. Generally, a stage block visualizes the Jenkins pipeline process.
Let's see an example for multiple stages, where each stage performs a specific task:
AD
pipeline {  
    agent any  
    stages {  
            stage ('Build') {  
                ...  
            }  
            stage ('Test') {  
                ...  
            }  
            stage ('QA') {  
                ...  
            }  
            stage ('Deploy') {  
                ...  
            }  
            stage ('Monitor') {  
                ...  
            }  
    }  
}  
Step: A step is a single task that executes a specific process at a defined time. A pipeline involves a series of steps defined within a stage block.
pipeline {  
    agent any  
    stages {  
            stage ('Build') {  
                steps {  
                        echo 'Running build phase...'  
                }  
            }  
    }  
}  

Jenkins Pipeline
In Jenkins, a pipeline is a collection of events or jobs which are interlinked with one another in a sequence.
It is a combination of plugins that support the integration and implementation of continuous delivery pipelines using Jenkins.
In other words, a Jenkins Pipeline is a collection of jobs or events that brings the software from version control into the hands of the end users by using automation tools. It is used to incorporate continuous delivery in our software development workflow.
A pipeline has an extensible automation server for creating simple or even complex delivery pipelines "as code", via DSL (Domain-specific language).
A sample Scripted pipeline
node{
stage('Compile'){
			steps {
				echo "Compiled Successfully!!";
			}
		}

	stage('JUnit') {
			steps {
				echo "JUnit Passed Succesfully!";
			}
		}

	stage('Quality-Gate') {
			steps {
				echo "SonarQube Quality Gate passed succesfully!!";
						/*sh exit ("1");*/
			}
		}

	stage('Deploy') {
			steps {
				echo "Pass!";
			}
		}
	}
A sample Groovy script Declarative pipeline
pipeline {
	agent any
	stages {
		stage('Git-Checkout'){
					steps {
						echo "Checking out from Git Repo";
						}
				}

		stage('Build') {
					steps {
						echo "Building the checkedout project!";
						}
				}

		stage('Unit-Test') {
					steps {
						echo "Running JUnit tests";
					}
				}
		stage('Quality-Gate') {
					steps {
						echo "Verifying Quality Gates";
					}
				}

		stage('Deploy') {
					steps {
						echo "Deploying to stage environments for more tests";
					}
				}
		}
	
		post {
			always {
					echo 'This will always run'
				}
			success {
					echo 'This will run only if successful'
				}
			failure {
					echo 'This will run only if failed'
				}
			unstable {
					echo 'This will run only if the run was marked as unstable'
				}
	    		changed {
					echo 'This will run only if the state of the pipeline has changed'
					echo 'For example, if the pipeline was previously failing but is now successful'
				}
   		 }
}


A MASTER-SLAVE Groovy script Declarative Pipeline

pipeline {
	agent none
	stages {
		stage('Non-parallel Stage'){
			agent {
				label "built-in";
				}

			steps {
					echo 'This stage will be executed first';
				}
		}

		stage('Run Tests') {
			parallel {
				stage('Test on Windows') {
					agent {
						label "slave_node1";
					}

					steps {
						echo "Task1 on Agent";
					}
				}

				stage('Test on Master') {
					agent {
							label "built-in";
						}	
					steps {
						echo "Task1 on Master";
					}
				}

				
			}
		}
}
}
